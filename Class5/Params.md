# Ollama 参数调节指南

## 常用参数表

| 参数名                | 推荐范围           | 作用说明                                   | 典型用途                              |
| --------------------- | ------------------ | ------------------------------------------ | ------------------------------------- |
| **temperature**       | 0.1–1.2            | 控制生成的发散度；越高越有创意，越低越稳定 | 0.2（代码）、0.7（聊天）、1.0（创意） |
| **top_p**             | 0.8–1.0            | “核采样”，限制在概率前 P% 的词中采样       | 通用对话常用 0.9–0.95                 |
| **top_k**             | 20–100             | 只从概率最高的前 K 个词中采样              | 小模型常用 40 限制噪声                |
| **repeat_penalty**    | 1.05–1.3           | 抑制重复句子/词语；越大重复越少            | 生成长文、避免循环                    |
| **presence_penalty**  | 0–1.5              | 惩罚已出现的概念，促进话题多样性           | 灵感生成、脑暴                        |
| **frequency_penalty** | 0–2.0              | 惩罚高频词，避免啰嗦                       | 文章写作、摘要                        |
| **num_predict**       | 50–2048+           | 最大生成 token 数                          | 限制回答长度                          |
| **num_ctx**           | 根据模型 (2k–128k) | 上下文窗口大小（内存决定）                 | 长文、多轮对话                        |
| **seed**              | 任意整数           | 固定随机性，使输出可复现                   | 测试、评估                            |
| **stop**              | 字符串数组         | 遇到指定词/符号立即停止生成                | 格式生成、代码边界                    |
| **mirostat**          | 0,1,2              | 启用 Mirostat 动态采样                     | 1 或 2（保持稳定困惑度）              |
| **mirostat_tau**      | 3–10               | 目标困惑度                                 | Mirostat 模式下调节稳定度             |
| **mirostat_eta**      | 0.1–1.0            | 调节 Mirostat 学习率                       | 输出收敛速度控制                      |
| **tfs_z**             | 1–2                | TFS sampling 控制尾部截断                  | 控制输出均匀性                        |
| **typical_p**         | 0.8–1.0            | Typical Sampling，避免平庸/异常词          | 更自然的文本                          |
| **penalize_newline**  | true / false       | 是否惩罚换行符                             | 避免模型生成过多空行                  |
| **rope_scale**        | 0.8–2.0            | 外推 RoPE，增强长文本能力（实验性）        | 长上下文优化                          |

## Python 调用示例

```python
import ollama

resp = ollama.generate(
    model='llama3.2:1b',
    prompt='解释一下量子叠加',
    options={
        "temperature": 0.7,
        "top_p": 0.95,
        "repeat_penalty": 1.1,
        "num_predict": 200
    }
)

print(resp["response"])
```
